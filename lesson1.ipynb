{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "k0EFG0yj3qKb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Занятие 1. Вводное"
      ]
    },
    {
      "metadata": {
        "id": "3Tjm6qN03vEq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Введение (для тех, кто еще не понял, зачем он здесь)"
      ]
    },
    {
      "metadata": {
        "id": "3LbhyqxV3znp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "В наше время, количество информации растет с невероятно большой скоростью. Человеку приходится работать с таким объемом данных, что уже на физическом уровне он не способен справиться с поставленной задачей. Поэтому машинное обучение все больше проникает в повседневную жизнь. <br>\n",
        "Алгоритмы машинного обучения используются уже во многих сферах:<br>\n",
        "•\tВ поисковых машинах доля поиска ответов на запрос;<br>\n",
        "•\tДля имитации личности (deep fake, lyrebird)<br>\n",
        "•\tВ робототехнике (Boston dynamics)<br>\n",
        "•\tВ рекомендательных системах и экспертных системах;<br>\n",
        "•\tВ обеспечении безопасности (распознавание лиц и т.д.).<br>\n",
        "Кроме того, есть информация, что благодаря нейронным сетям можно стать президентом США… (в 2012 году на время предвыборной кампании Барак Обама назначил Раида Гани, эксперта по машинному обучению, главным аналитиком) (если что, то победил Обама).<br>\n",
        "Подводя итог, можно сказать, что нейронные сети откроют вам дорогу в светлое будущее. Они могут сделать невозможное возможным. Надо только захотеть.<br>\n"
      ]
    },
    {
      "metadata": {
        "id": "Um5ooUup4D-8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Теоретическая часть"
      ]
    },
    {
      "metadata": {
        "id": "-5VeVipf4F3G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Здесь будет рассказано о том, что такое нейронные сети.<br><br>\n",
        "Нейронные сети - это один из многих алгоритмов машинного обучения, позволяющий разделить данные на классы. Нейронная сеть выделяется среди этих алгоритмов тем, что её механизм получения результата схож с процессом работы нейронов в нашем мозге.<br>\n",
        "![alt text](https://leonardo.osnova.io/9f49d911-e30d-f9af-5046-d608cf3e68be/-/scale_crop/520x241/center/) <br>\n",
        "Рассмотрим модель биологического нейрона. В ней мы можем выделить несколько ос-новных частей: дендрит, аксон и синапс. Дендрит связан с внешним воздействием на нейрон. В аксоне выделяется межклеточное вещество. Количество этого вещества определя-ет, как среагирует синапс, связанный с дендритами других нейронов. Поэтому, видя какой-либо предмет, в нейронах человека каждый раз выделяется примерно одно и то же количе-ство межклеточного вещества. Примерно так устроена наша память и работа искусственного нейрона. Проведём аналогию с искусственными нейронами.<br>\n",
        "![alt text](https://github.com/Lavabar/My-Neural-Networks-Course/raw/master/images/pic1.png)<br>\n",
        "В простой модели искусственного нейрона (перцептроне) так же есть дендрит, аксон и синапс. На входной узел i поступают данные (то есть числа). Далее, они обрабатываются с помощью веса w. И выдают результат через выход o. Теперь о том, что значит «обрабатыва-ются» и что означает тот квадратик с надписью «Threshold». В первом случае находится сумма произведений пар значений (ik, wk), а во втором случае наша сумма проходит через активационную функцию. В данном случае в качестве активационной функции выступает Threshold, но существует еще и много других (самые распространенные sigmoid(S), tanh(S), softmax(S)).\n",
        "<br>\n",
        "Теперь нужно вспомнить, что в словосочетании «нейронная сеть» есть слово «сеть».\n",
        "<br>\n",
        "![alt text](https://habrastorage.org/getpro/habr/post_images/e61/3db/569/e613db56971c92a6dedae728ef6997e0.png)\n",
        "<br>\n",
        "Что мы здесь видим. Входными сигналами в данном случае считаются синие вершины графа (входной слой). Красными точками являются значения, полученные в результате работы активационной функции нашей нейронной сети (скрытый слой). Далее эти значения подаются в качестве входных для слоя зеленых точек (выходной слой), где они так же обрабатываются и подаются в активационную функцию. Результатом работы нейронной сети является набор выходных значений зеленых точек, каждую из которых можно интерпретировать как коэффициент принадлежности входных данных (значений синих точек) к одному из классов.\n",
        "<br>\n",
        "![alt text](https://github.com/Lavabar/My-Neural-Networks-Course/raw/master/images/pic2.jpg)\n",
        "<br>\n",
        "Теперь нужно поговорить о самом главном. Откуда нам брать значения для весов w. Ответ на этот вопрос лежит в понятии «обучения» нейронной сети. Обучение нейронной сети – это «подстройка» весов сети таким образом, чтобы она выдавала необходимый результат на определенные входные данные. Все происходит так.<br> \n",
        "Вы создали нейронную сеть. Задали количество слоев, количество нейронов на каждом слое, выбрали функции активации. После этого всего в вашей сети происходит инициализация весов на каждом слое. Веса задаются случайным образом, так как в таком случае больше вероятность попасть сразу в цель.<br>\n",
        "Перед тем, как начать обучение нейронной сети, вы должны где-то найти обучающую выборку для нее (обучающая выборка – это когда у вас есть множество наборов входных данных и соответствующие им выходные данные). После этого берете первый набор входных данных и прогоняете через нейронную сеть. Теперь у вас есть выходные значения, которые дала сеть и выходные значения, которые вы от нее ждали. На основе разницы этих значений корректируются значения весов сети. Все происходит с помощью метода обратного распространения ошибки. Грубо говоря, в этом методе мы считаем «ошибку» для каждого нейрона, далее проходим по каждому весу сети и считаем для него значение оптимизационной функции (среди них могут быть sgd, adam, rmsprop) и это значение прибавляем к текущему значению веса. В итоге мы получаем нейронную сеть с новыми, более подходящими для нашей задачи весами. Важно отметить, что функция оптимизации дает лишь корректировочное значение для определенного веса, но никак не конечные значения. То есть, чтобы обучить нейронную сеть необходимо применить метод обратного распространения ошибки (backpropagation) несколько раз (много).\n"
      ]
    },
    {
      "metadata": {
        "id": "b2TdRXim7Vx3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Практическая часть"
      ]
    },
    {
      "metadata": {
        "id": "7TfNWkyi73qb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Теперь попробуем подкрепить практику теорией.<br>\n",
        "(Чтобы не заморачиваться с установкой всяких библиотек и не засорять свой комп, советую воспользоваться google colaboratory https://colab.research.google.com . Разобраться очень просто, почекайте examples)<br>\n",
        "Для того, чтобы продолжить дальше, вам необходимо установить numpy, tensorflow и keras (лучше это сделать именно в таком порядке) при помощи pip.\n"
      ]
    },
    {
      "metadata": {
        "id": "KnRCUeCCezYo",
        "colab_type": "code",
        "outputId": "448d9ca5-c14f-42a2-fc92-98e72ea58cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.12.0rc1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.6.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.32.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.5)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.5.0)\n",
            "Requirement already satisfied: tensorboard<1.12.0,>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.6)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.4.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "muSx0NuM8Cp-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Во время установки соглашайтесь на установление всех зависимостей. <br>\n",
        "Теперь остановимся подробнее на numpy, а дальше перейдем сразу к нейронкам.<br>\n",
        "###Интенсив по numpy\n",
        "NumPy — это библиотека языка Python, добавляющая поддержку больших многомерных массивов и матриц, вместе с большой библиотекой высокоуровневых (и очень быстрых) математических функций для операций с этими массивами. Это очень мощный инструмент для работы с вашими данными, старайтесь использовать его, как можно чаще.<br>\n",
        "Основным объектом NumPy является однородный многомерный массив (в numpy называется numpy.ndarray). Это многомерный массив элементов (обычно чисел), одного типа.<br>\n",
        "Наиболее важные атрибуты объектов ndarray:<br>\n",
        "•\tndarray.shape - размеры массива, его форма. Это кортеж натуральных чисел, показывающий длину массива по каждой оси. Для матрицы из n строк и m столбов, shape будет (n,m). Число элементов кортежа shape равно ndim.<br>\n",
        "•\tndarray.size - количество элементов массива. Очевидно, равно произведению всех элементов атрибута shape.<br>\n",
        "•\tndarray.dtype - объект, описывающий тип элементов массива.<br>\n",
        "<br>\n",
        "В NumPy существует много способов создать массив. Один из наиболее простых - создать массив из обычных списков или кортежей Python, используя функцию numpy.array() (запомните: array - функция, создающая объект типа ndarray):\n",
        "<br>"
      ]
    },
    {
      "metadata": {
        "id": "t_VbkGxS8RrN",
        "colab_type": "code",
        "outputId": "693d1c35-0227-497c-8dc4-cb6c8c14034c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([1, 2, 3])\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "_3HTcbSU8hFX",
        "colab_type": "code",
        "outputId": "db4a34e0-acd7-41ba-d469-4509da766867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "b = np.array([[1.5, 2, 3], [4, 5, 6]])\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.5, 2. , 3. ],\n",
              "       [4. , 5. , 6. ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "037r9u0q8j1h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Функция zeros() создает массив из нулей, а функция ones() — массив из единиц. Обе функции принимают кортеж с размерами, и аргумент dtype:"
      ]
    },
    {
      "metadata": {
        "id": "Thd4PzwL8lf9",
        "colab_type": "code",
        "outputId": "b72cc51f-45ba-4c59-c387-5e88a6d29175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "np.zeros((3, 5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "jxitQg8B8n_9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Для создания последовательностей чисел, в NumPy имеется функция arange(), аналогичная встроенной в Python range(), только вместо списков она возвращает массивы, и принимает не только целые значения:"
      ]
    },
    {
      "metadata": {
        "id": "j_bxeD208qtA",
        "colab_type": "code",
        "outputId": "c6d01437-3920-46b9-e59d-7a6328980ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "np.arange(10, 30, 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10, 15, 20, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "6_w3zXOK84Ny",
        "colab_type": "code",
        "outputId": "c2adc761-fb13-4a81-97f2-83e13c0edea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "np.arange(0, 1, 0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "aN9QVtCd8wEO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "На этом пока остановимся. Теперь перейдем к самому интересному. Для начала попробуем написать нейронную сеть, которая бы распознавала рукописные цифры."
      ]
    },
    {
      "metadata": {
        "id": "wodE_DSr86fk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Создаем нейронную сеть на keras"
      ]
    },
    {
      "metadata": {
        "id": "wk4YRJ0ocVaz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "В keras уже есть некоторые датасеты, поэтому мы пока просто воспользуемся одним из них, чтобы не терять время. \n",
        "Импортируем из кераса датасет с рукописными цифрами mnist и сразу же загрузим его.\n",
        "В X_train и X_test у нас будут лежать картинки, а в Y_train и Y_test ответы. "
      ]
    },
    {
      "metadata": {
        "id": "24GYGz44blAz",
        "colab_type": "code",
        "outputId": "208535a9-bad3-46c2-e969-efea2534f161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_LsdHfs5dk8w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Теперь посмотрим, что у нас скачалось и в каком виде представлены данные. Перед этим обратите внимание на тип данных скачанного датасета"
      ]
    },
    {
      "metadata": {
        "id": "XdAZ0048d2b4",
        "colab_type": "code",
        "outputId": "d1f7ffdd-a7a6-4661-8c2d-972f2a35fe0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(type(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2qkaxl_YePPi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Keras и многие другие фреймворки использует numpy.ndarray в качестве основного типа данных. Поэтому воспользуемся нашими знаниями по numpy и распечатаем shape наших данных"
      ]
    },
    {
      "metadata": {
        "id": "7to5WhjbboEv",
        "colab_type": "code",
        "outputId": "e3aa05ed-ee74-427f-d52f-5c3adef8cd5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pq_tYnOCen7o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Получается, что у нас входные данные представлены в виде массива матриц 28х28 (то есть это просто картинка в привычном нам виде), а выходные в виде массива цифр. Мы же, в нашей сети будем эти данные использовать в ином виде. Нам нужно чтобы входные данные были представлены не в виде последовательности матриц, а в виде последовательности одномерных массивов. То  есть нам нужно вытянуть наши картинки в 1 ряд. Выходные же данные надо представить в т.н hot-vector виде. Это когда:\n",
        "0 = (1, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
        "1 = (0, 1, 0, 0, 0, 0, 0, 0, 0, 0)\n",
        "2 = (0, 0, 1, 0, 0, 0, 0, 0, 0, 0)\n",
        "и т.д\n",
        "Для входных данных воспользуемся методом reshape, а для выходных данных надо будет импортировать из keras утилиту to_categorical."
      ]
    },
    {
      "metadata": {
        "id": "-NeuIDmecRUZ",
        "colab_type": "code",
        "outputId": "bdb070dd-c6b4-4a8d-b648-afa151f7b47a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(60000, 784) # 28*28 == 784\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "Y_train = to_categorical(Y_train, 10) # 10 - количество цифр\n",
        "Y_test = to_categorical(Y_test, 10)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PxnQY043iEOV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Отлично! Теперь подробнее рассмотрим входные данные"
      ]
    },
    {
      "metadata": {
        "id": "6ELG7Qvdh1rk",
        "colab_type": "code",
        "outputId": "466a0523-a4b6-4fe1-810a-cbdce7ea0359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "cell_type": "code",
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
            " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
            " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
            "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
            "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
            " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
            " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
            " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
            "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RuMMwJOwiO81",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Как вы можете заметить, у нас тут числа от 0 до 255, но так не пойдет. Нейронные сети работают с нормализованными данными. Это обусловнено тем, что на вход могут подаваться данные совершенно разного типа и характера. Например, часть значений может быть от 0 до 255, а другая часть значений от 4 до 36,5. И если оставить значения в таком виде, то нейросеть будет вопринимать максимальное значение 36,5 как не очень большое, потому что есть еще 255. Но и 36,5 и 255 должны иметь одинаковую силу. Поэтому мы сейчас нормализуем наши входные данные (то есть приведем их к виду [0, 1]). Для этого преобразуем целые числа в вещественные и поделим все значения на максимально возможное"
      ]
    },
    {
      "metadata": {
        "id": "7Rv1IhxuiIU0",
        "colab_type": "code",
        "outputId": "f5995f87-1209-482f-97f0-846299fbf449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2288
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
            " 0.96862745 0.49803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.19215687\n",
            " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
            " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
            " 0.96862745 0.94509804 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.04313726\n",
            " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13725491 0.94509804\n",
            " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
            " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            " 0.5882353  0.10588235 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.15294118 0.5803922\n",
            " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07058824 0.67058825\n",
            " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
            " 0.3137255  0.03529412 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.53333336 0.99215686\n",
            " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9-iwghPVoUZ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Замечательно! Ну теперь точно все, начинаем.."
      ]
    },
    {
      "metadata": {
        "id": "6HBI_mf2oe8t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Сначала импортируем все, что нам нужно для создания и обучения модели искусственной нейронной сети.<br>\n",
        "В Керасе есть два вида моделей. Это Sequential и  Model. Sequential это модель, где слои соединены последовательно, один за другим (то есть один входной слой и один выходной). Model - это базовый класс Sequential, то есть используя его, вы получаете некоторую свободу действий и можете проявить свою творческую натуру. <br>\n",
        "Что касается Dense, то это класс слоя, который называется полносвязным (то есть у него все входы связаны со всеми выходами предыдущего слоя и все выходы связаны со всеми входами следующего)"
      ]
    },
    {
      "metadata": {
        "id": "ofiF3jGnny7X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJ406wP4pgT2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Создадим нейросеть\n",
        "<br>\n",
        "![alt text](https://habrastorage.org/getpro/habr/post_images/e61/3db/569/e613db56971c92a6dedae728ef6997e0.png)\n",
        "<br>\n",
        "Получится она у нас примерно вот такого вида. Только у нас будет 784 синих вершин, 800 красных и 10 зеленых :) <br>\n",
        "Первый полносвязный слой у нас вышел с 784 входами и 800 нейронами, каждый из которых будет активироваться функцией relu\n",
        "Второй с 800 входами и 10 выходами и функцией softmax\n",
        "<br>\n",
        "Скомпилируем модель, добавляя в нее следующие свойства:<br>\n",
        "Функция подсчета ошибки - categorical_crossentropy<br>\n",
        "Функция оптимизации весов - adam<br>\n",
        "Показатель работы нейронной сети - accuracy (то есть количество правильно распознанных данных на количество всех)\n",
        "<br><br>(Если вам будет очень интересно, то попробуйте поподставлять другие методы loss и optimization из документации кераса и посмотрите, как будет меняться результат)"
      ]
    },
    {
      "metadata": {
        "id": "gwTcQS2IpfXf",
        "colab_type": "code",
        "outputId": "001d92ea-2bf2-4487-d526-d3166a513bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(800, input_dim=784, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 800)               628000    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                8010      \n",
            "=================================================================\n",
            "Total params: 636,010\n",
            "Trainable params: 636,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b-ulgkgOsxB3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Прежде чем начинать обучение поговорим о стратегиях обучения...<br>\n",
        "Обучение можно производить тремя методами: стохастический метод (stochastic), пакетный метод (batch) и мини-пакетный метод (mini-batch). Существует очень много статей и исследований на тему того, какой из методов лучше и никто не может прийти к общему ответу.\n",
        "\n",
        "Вкратце о каждом методе:\n",
        "\n",
        "Стохастический (его еще иногда называют онлайн) метод работает по следующему принципу — нашел Δw, сразу обнови соответствующий вес.\n",
        "\n",
        "Пакетный метод же работает по другому. Мы суммируем Δw всех весов на текущей итерации и только потом обновляем все веса используя эту сумму. Один из самых важных плюсов такого подхода — это значительная экономия времени на вычисление, точность же в таком случае может сильно пострадать.\n",
        "\n",
        "Мини-пакетный метод является золотой серединой и пытается совместить в себе плюсы обоих методов. Здесь принцип таков: мы в свободном порядке распределяем веса по группам и меняем их веса на сумму Δw всех весов в той или иной группе.\n",
        "<br>\n",
        "За обучение нейронки в керасе отвечает метод fit. В качестве параметров он принимает входные данные, выходные данные, размер мини-пакета (1, если стохастический и 60000, если пакетный), количество итераций обучения нейронной сети (1 итерация - это прого всех примеров из обучающей выборки), процент данных выборки, который пойдет на валидацию (то есть на предварительную оценку качества обучения)\n",
        "\n",
        "Мы в данном случае применим мини-пакетный метод обучения и будем менять веса после каждых 200 изображений.\n",
        "<br>\n",
        "Прогоним все изображения 25 раз подряд\n",
        "<br>\n",
        "На валидацию будет уходить 20% избражений\n",
        "<br>\n",
        "<br>\n",
        "verbose - это режим вывода логов"
      ]
    },
    {
      "metadata": {
        "id": "3BjHfIuarCo8",
        "colab_type": "code",
        "outputId": "bf7d55a7-2341-4536-862c-c1683c578df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, Y_train, batch_size=200, epochs=25, validation_split=0.2, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/25\n",
            " - 5s - loss: 1.9070e-05 - acc: 1.0000 - val_loss: 0.0945 - val_acc: 0.9836\n",
            "Epoch 2/25\n",
            " - 5s - loss: 1.6436e-05 - acc: 1.0000 - val_loss: 0.0954 - val_acc: 0.9828\n",
            "Epoch 3/25\n",
            " - 5s - loss: 1.4608e-05 - acc: 1.0000 - val_loss: 0.0959 - val_acc: 0.9833\n",
            "Epoch 4/25\n",
            " - 5s - loss: 1.2818e-05 - acc: 1.0000 - val_loss: 0.0968 - val_acc: 0.9830\n",
            "Epoch 5/25\n",
            " - 5s - loss: 1.1419e-05 - acc: 1.0000 - val_loss: 0.0973 - val_acc: 0.9834\n",
            "Epoch 6/25\n",
            " - 5s - loss: 1.0229e-05 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 0.9836\n",
            "Epoch 7/25\n",
            " - 5s - loss: 8.9668e-06 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9833\n",
            "Epoch 8/25\n",
            " - 5s - loss: 7.8521e-06 - acc: 1.0000 - val_loss: 0.0988 - val_acc: 0.9830\n",
            "Epoch 9/25\n",
            " - 5s - loss: 7.1381e-06 - acc: 1.0000 - val_loss: 0.0987 - val_acc: 0.9835\n",
            "Epoch 10/25\n",
            " - 5s - loss: 6.3087e-06 - acc: 1.0000 - val_loss: 0.0995 - val_acc: 0.9833\n",
            "Epoch 11/25\n",
            " - 5s - loss: 5.5889e-06 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9835\n",
            "Epoch 12/25\n",
            " - 5s - loss: 5.0054e-06 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9834\n",
            "Epoch 13/25\n",
            " - 5s - loss: 4.4346e-06 - acc: 1.0000 - val_loss: 0.1011 - val_acc: 0.9837\n",
            "Epoch 14/25\n",
            " - 5s - loss: 3.9358e-06 - acc: 1.0000 - val_loss: 0.1024 - val_acc: 0.9838\n",
            "Epoch 15/25\n",
            " - 5s - loss: 3.5567e-06 - acc: 1.0000 - val_loss: 0.1026 - val_acc: 0.9837\n",
            "Epoch 16/25\n",
            " - 5s - loss: 3.0714e-06 - acc: 1.0000 - val_loss: 0.1033 - val_acc: 0.9838\n",
            "Epoch 17/25\n",
            " - 5s - loss: 2.7241e-06 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9834\n",
            "Epoch 18/25\n",
            " - 5s - loss: 2.4389e-06 - acc: 1.0000 - val_loss: 0.1037 - val_acc: 0.9838\n",
            "Epoch 19/25\n",
            " - 5s - loss: 2.1354e-06 - acc: 1.0000 - val_loss: 0.1042 - val_acc: 0.9834\n",
            "Epoch 20/25\n",
            " - 5s - loss: 1.9007e-06 - acc: 1.0000 - val_loss: 0.1059 - val_acc: 0.9837\n",
            "Epoch 21/25\n",
            " - 5s - loss: 1.7263e-06 - acc: 1.0000 - val_loss: 0.1056 - val_acc: 0.9843\n",
            "Epoch 22/25\n",
            " - 5s - loss: 1.5403e-06 - acc: 1.0000 - val_loss: 0.1061 - val_acc: 0.9838\n",
            "Epoch 23/25\n",
            " - 5s - loss: 1.3707e-06 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 0.9839\n",
            "Epoch 24/25\n",
            " - 5s - loss: 1.2158e-06 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9837\n",
            "Epoch 25/25\n",
            " - 5s - loss: 1.0747e-06 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YMAmVCM10uS6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ура! Теперь, после небольшого ожидания проверим, как нейронная сеть обучилась. Для этого воспользуемся тестовыми данными."
      ]
    },
    {
      "metadata": {
        "id": "0HxWdfUd1bt9",
        "colab_type": "code",
        "outputId": "2b605d4c-7540-4f6f-fd2a-38e4aa3d1a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Точность работы на тестовых данных: 98.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YhGJucJv1iQS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Получается, что наша сеть смогла правильно распознать почти все тестовые примеры (заметьте, что раньше она эти данные не видела)"
      ]
    },
    {
      "metadata": {
        "id": "HG6mGELf0YAf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "exmpl = 432 # попробуем получить результат из 432 изображения\n",
        "x = X_test[exmpl]\n",
        "x = np.expand_dims(x, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wXbyChyD21a8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Более наглядно показано, что мы только что сделали..."
      ]
    },
    {
      "metadata": {
        "id": "CkyX22IJ1L1a",
        "colab_type": "code",
        "outputId": "0b4a7996-1c4d-4e87-d1fb-fc4698b15170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "### Просто пример\n",
        "abc = np.array([1, 2, 3])\n",
        "\n",
        "bcd = np.expand_dims(abc, axis=0)\n",
        "\n",
        "abc = np.asarray([abc])\n",
        "\n",
        "print(abc.shape)\n",
        "print(bcd.shape)\n",
        "###"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3)\n",
            "(1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "07_jWpSz3IH4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "И напоследок зафигачим предикшон"
      ]
    },
    {
      "metadata": {
        "id": "GYwW7OPt20E7",
        "colab_type": "code",
        "outputId": "b551b27c-c888-488e-c5b4-6768936afc7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "predict = model.predict(x)\n",
        "print(predict)\n",
        "number = np.argmax(predict)\n",
        "print(number)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.2222338e-14 7.6561896e-08 3.1316326e-06 1.0312326e-06 9.9895132e-01\n",
            "  1.0369174e-03 6.4486403e-06 4.2626263e-07 3.7438950e-09 6.5984528e-07]]\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "siyZCajE3YDq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Вот и все, в принципе)"
      ]
    },
    {
      "metadata": {
        "id": "-E1rkBzbC7-y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Если у вас еще остались вопросы"
      ]
    },
    {
      "metadata": {
        "id": "2RNARoabDPxq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://habr.com/post/369349/ (забавное объяснение нейронных сетей, которое поможет глубже погрузиться в тему)<br>\n",
        "https://pythonworld.ru/numpy/1.html (туториал по numpy)<br>\n",
        "https://habr.com/post/352678/ (другой туториал по numpy)<br>\n",
        "[Подробнее о функциях активации можно найти здесь](https://edu.kpfu.ru/pluginfile.php/288277/mod_wiki/attachments/158/%D0%9D%D0%B0%D0%B3%D0%BC%D0%B0%D1%82%D1%83%D0%BB%D0%BB%D0%B8%D0%BD_%D0%A2%D0%B8%D0%BC%D1%83%D1%80_%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5 %D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%BE%D0%B9 %D1%81%D0%B5%D1%82%D0%B8. %D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F %D0%B0%D0%BA%D1%82%D0%B8%D0%B2%D0%B0%D1%86%D0%B8%D0%B8 %D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%BE%D0%B9 %D1%81%D0%B5%D1%82%D0%B8..docx?forcedownload=1)<br>\n",
        "https://www.asozykin.ru/courses/nnpython (крутой дядька, который рассказывает, как писать нейросети на keras)<br>\n",
        "https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A (тоже крутой дядька, но английском)<br>\n",
        "Если у вас совсем все плохо или вы нашли несоответствие с действительностью, то можно написать в телеге (@lavabar) или по почте (lavabarser@gmail.com)\n"
      ]
    },
    {
      "metadata": {
        "id": "5Z4A2SboAWSG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Документация"
      ]
    },
    {
      "metadata": {
        "id": "xSCg3memAZSv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://devdocs.io/numpy/ <br>\n",
        "https://keras.io/"
      ]
    },
    {
      "metadata": {
        "id": "cMRPgYjaE1k9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Внеклассное чтение"
      ]
    },
    {
      "metadata": {
        "id": "mosMjW4_E5U7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://habr.com/post/271563/ (тут на Питоне написана очень простая нейронка без фреймворков)<br>\n",
        "https://habr.com/post/272679/ (придет лучшее понимание методов оптимизации весов, объяснение на интуитивных примерах) <br>\n",
        "https://habr.com/post/198268/ (хорошая статья про обучение нейронных сетей)<br>\n",
        "https://habr.com/post/307004/ (больше математики)\n"
      ]
    },
    {
      "metadata": {
        "id": "zhZR2CU8ASti",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Домашнее задание"
      ]
    },
    {
      "metadata": {
        "id": "CxUweggNBaUg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Необходимо написать нейронную сеть для анализа тональности текста на основе всего того, что мы сегодня прошли. \n",
        "<br>\n",
        "Смысл: Вы вводите в бота сообщение: \"Какой замечательный день\", а бот выводит: \"Хорошо/плохо на 76%\"<br>\n",
        "<br>\n",
        "Рекомендации:<br>\n",
        "https://www.kaggle.com/c/sentiment-analysis-in-russian - датасет(https://stackoverflow.com/questions/20199126/reading-json-from-a-file)<br>\n",
        "Необходимо будет изучить keras.preprocessing.text.Tokenizer и keras.preprocessing.sequence.pad_sequences<br>\n",
        "Также изучите работу слоя Embedding в keras<br>\n",
        "Все это вам очень пригодится для представления слов в виде, удобном для нейронки."
      ]
    },
    {
      "metadata": {
        "id": "vbkQqmca3V4J",
        "colab_type": "code",
        "outputId": "afdccdfe-8d46-4549-adc9-72d1bf968835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "### Примерный вариант использования Tokenizer и pad_sequences\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "text_base = np.array(['егор пошел домой', 'ему очень сильно нравятся нейронные сети', 'предложение со случайными словами'])\n",
        "\n",
        "max_fatures = 15\n",
        "#max_fatures = 10 \n",
        "# Обратите внимание на то, что если max_fatures сделать слишком маленьким,\n",
        "# то тогда вы можете потерять информацию. Оценивайте количество возможных слов правильно\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(text_base)\n",
        "X = tokenizer.texts_to_sequences(text_base)\n",
        "X = pad_sequences(X)\n",
        "print(X)\n",
        "# Дальше все это дело подается на вход слоя Embedding"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  1  2  3]\n",
            " [ 4  5  6  7  8  9]\n",
            " [ 0  0 10 11 12 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U0h4Z0OcIY5f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}